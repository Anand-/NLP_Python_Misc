{
 "metadata": {
  "gist_id": "8701b95a84cf9f88dab1",
  "name": "",
  "signature": "sha256:1f2bd8da19210493923f7d27752e0db89c663a28b6139b72fac981009342667e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Methods to retrieve data from my text collection (\"Surely you're joking, Mr. Feynman!\") and from the brown corpus."
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "(Algorithms are after these)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This cell has all methods I need, covering all the different operations I might need to do with my text.\n",
      "import nltk\n",
      "import re\n",
      "import string\n",
      "from nltk.corpus import stopwords\n",
      "from urllib import urlopen\n",
      "\n",
      "#Get Feynman\n",
      "def ReadFeynman():\n",
      "    url = 'https://archive.org/stream/RichardFeynman/Richard_P_Feynman-Surely_Youre_Joking_Mr_Feynman_v5_djvu.txt'\n",
      "    raw = urlopen(url).read()\n",
      "    modified = raw[10150:]\n",
      "    modified = string.replace(modified,'\\n','')\n",
      "    modified = string.replace(modified,'\\xe2\\x80\\x94','')\n",
      "    return modified\n",
      "\n",
      "#Get sentences from Feynman\n",
      "def GetSentencesFromFeynman():\n",
      "    sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "    sents = sent_tokenizer.tokenize(ReadFeynman())\n",
      "    return sents\n",
      "\n",
      "#Get words from Feynman\n",
      "def GetWordsFromFeynman():\n",
      "    pattern = r\"([A-Z]\\.)+|\\w+([-']\\w+)*|\\$?\\d+(\\.\\d+)?%?|\\.\\.\\.|[][.,;\\\"'?():-_`]\"\n",
      "    words = nltk.regexp_tokenize(ReadFeynman(), pattern)\n",
      "    return words\n",
      "    \n",
      "\n",
      "#Tag the Feynman\n",
      "def GetTaggedSentences(all_sentences):\n",
      "    pattern = r\"([A-Z]\\.)+|\\w+([-']\\w+)*|\\$?\\d+(\\.\\d+)?%?|\\.\\.\\.|[][.,;\\\"'?():-_`]\"\n",
      "    sentences = all_sentences\n",
      "    split_sents = [nltk.regexp_tokenize(sent, pattern) for sent in sentences]\n",
      "    tagged_sents = []\n",
      "    ngram_tagger = GetTrainedNGramTagger()\n",
      "    for sent in split_sents:\n",
      "        tagged_sents.append(ngram_tagger.tag(sent))\n",
      "    return tagged_sents\n",
      "\n",
      "#First define a tagger\n",
      "def build_backoff_tagger (train_sents):\n",
      "    t0 = nltk.DefaultTagger('NN')\n",
      "    t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
      "    t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
      "    return t2\n",
      "\n",
      "#Training and buildng the ngram tagger\n",
      "def GetTrainedNGramTagger():\n",
      "    #Build training set\n",
      "    train_sents = []\n",
      "    for categ in nltk.corpus.brown.categories():\n",
      "        for sent in nltk.corpus.brown.tagged_sents(categories=categ):\n",
      "            train_sents.append(sent)\n",
      "    train_sents.append([('Feynman', 'NP')])\n",
      "    train_sents.append([('Los', 'NP'),('Alamos', 'NP')])\n",
      "    train_sents.append([('MIT', 'NP')])\n",
      "    #training the tagger\n",
      "    ngram_tagger = build_backoff_tagger(train_sents)\n",
      "    return ngram_tagger\n",
      "    \n",
      "#Gets you the verbs\n",
      "def VerbChunker(sent):\n",
      "    grammar = \"VERB: {<VBD>}\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    result = cp.parse(sent)\n",
      "    return result\n",
      "\n",
      "#Gets you the noun phrases\n",
      "def SlightlyModifiedChuangChunker(sent):\n",
      "    grammar = \"NP: {<CD>*(((<JJ>|<N.*>)+(<N.*>|<CD>))|<N.*>)}\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    result = cp.parse(sent)\n",
      "    return result\n",
      "\n",
      "#Gets you the noun phrases\n",
      "def NounPhraseChunker(sent):\n",
      "    grammar = \"NP: {<CD>*(((<JJ.*>|<N.*>)+(<N.*>|<CD>)*)|<N.*>)}\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    result = cp.parse(sent)\n",
      "    return result\n",
      "\n",
      "#Gets you the noun phrases with the verbs\n",
      "def VerbSubjectChunker(sent):\n",
      "    grammar_np = \"(<CD>*(((<JJ.*>|<N.*>)+(<N.*>|<CD>)*)|<N.*>))\"\n",
      "    verb = \"(<V.*>)\"\n",
      "    grammar = \"VN: {\"+grammar_np+verb+grammar_np+\"}\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    result = cp.parse(sent)\n",
      "    return result\n",
      "\n",
      "\n",
      "#Run the chunker against a Chunker with a specific grammar\n",
      "def ChunkASection(sents,Chunker):\n",
      "    chunkedlist = []\n",
      "    for sent in sents:\n",
      "        chunks =  Chunker(sent)\n",
      "        for chunk in chunks:\n",
      "            if(type(chunk)==type(chunks)):\n",
      "                temp =''\n",
      "                for leaf in chunk.leaves():\n",
      "                    temp += leaf[0]+' '\n",
      "                chunkedlist.append(temp)\n",
      "    return chunkedlist\n",
      "\n",
      "#Run the chunker against a Chunker with a specific grammar\n",
      "def ChunkASectionForVerb(sents,Chunker,verb):\n",
      "    chunkedlist = []\n",
      "    for sent in sents:\n",
      "        chunks =  Chunker(sent,verb)\n",
      "        for chunk in chunks:\n",
      "            if(type(chunk)==type(chunks)):\n",
      "                temp =''\n",
      "                for leaf in chunk.leaves():\n",
      "                    temp += leaf[0]+' '\n",
      "                chunkedlist.append(temp)\n",
      "    return chunkedlist\n",
      "\n",
      "#Getting sentences which contain a specific word\n",
      "def GetSentencesWith(sents,word):\n",
      "    allSentences = []\n",
      "    pattern = r\"([A-Z]\\.)+|\\w+([-']\\w+)*|\\$?\\d+(\\.\\d+)?%?|\\.\\.\\.|[][.,;\\\"'?():-_`]\"\n",
      "    for sent in sents:\n",
      "        if word in nltk.regexp_tokenize(sent, pattern):\n",
      "            allSentences.append(sent)\n",
      "    return allSentences\n",
      "\n",
      "\n",
      "#Getting normalized words from Feynman - remove punct, stopwords and make it unicode \n",
      "def GetNormalizedWordsFromFeynman():\n",
      "    words = GetWordsFromFeynman()\n",
      "    #remove stop words\n",
      "    words = [w for w in words if w.lower() not in stopwords.words('english')]\n",
      "    #remove punctuation\n",
      "    words = [w for w in words if w not in string.punctuation]\n",
      "    #remove non unicode charcters\n",
      "    words = [unicode(word, errors='ignore') for word in words]\n",
      "    return words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get words, sentences, tagged words, tagged sentences from Brown\n",
      "def GetWordsFromBrown():\n",
      "    return nltk.corpus.brown.words(categories=\"news\")\n",
      "def GetSentencesFromBrown():\n",
      "    return nltk.corpus.brown.sents(categories=\"news\")\n",
      "def GetTaggedWordsFromBrown():\n",
      "    return nltk.corpus.brown.tagged_words(categories=\"news\")\n",
      "def GetTaggedSentencesFromBrown():\n",
      "    return nltk.corpus.brown.tagged_sents(categories=\"news\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get the mystery text\n",
      "def GetMysteryText():\n",
      "    text = open(\"C:\\Users\\st.johns\\Desktop\\mystery\\mystery.txt\").read()\n",
      "    text = string.replace(text,'\\n','')\n",
      "    return text\n",
      "\n",
      "#Get sentences \n",
      "def GetSentencesFromMystery(text):\n",
      "    sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "    sents = sent_tokenizer.tokenize(text)\n",
      "    return sents\n",
      "\n",
      "#Get words from Feynman\n",
      "def GetWordsFromMystery(text):\n",
      "    pattern = r\"([A-Z]\\.)+|\\w+([-']\\w+)*|\\$?\\d+(\\.\\d+)?%?|\\.\\.\\.|[][.,;\\\"'?():-_`]\"\n",
      "    words = nltk.regexp_tokenize(text, pattern)\n",
      "    return words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Algorithm 1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this algorithm, I am selecting the most frequently occuring bigrams from a collection of all the nouns in the collection.\n",
      "\n",
      "Procedure:\n",
      "1. Get all the words from the collection\n",
      "2. Remove the stop words and punctuation\n",
      "3. Convert to unicode to overcome the problem of non ASCII characters\n",
      "4. Remove all non-nouns from the list\n",
      "5. Find bigrams on the list\n",
      "6. Find the most frequently occuring bigrams\n",
      "7. Return the top 100 of the list\n",
      "\n",
      "This is intended to be a baseline algorithm. it indicates the most frequent noun bigrams, which in turn gives the most frequently talked about topics in the collection. \n",
      "\n",
      "This could be further improved if the resultant list could be grouped together such that topics are not repeated"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Method takes a lost of tagged words as parameter\n",
      "def MostFrequentBigrams(words):\n",
      "    #remove stop words\n",
      "    words = [(w,t) for (w,t) in words if w.lower() not in stopwords.words('english')]\n",
      "    #remove punctuation\n",
      "    words = [(w,t) for (w,t) in words if w not in string.punctuation]\n",
      "    #remove non unicode charcters\n",
      "    words = [(unicode(w, errors='ignore'),t) for (w,t) in words]\n",
      "    #filter out to get all the nouns\n",
      "    words = [(w,t) for (w,t) in words if re.match(r'N.*',t)]\n",
      "    #print words[:100]\n",
      "    words = [w for (w,t) in words]\n",
      "    \n",
      "    words_bigrams = nltk.bigrams(words)\n",
      "    for item in words_bigrams:\n",
      "        (w1,w2) = item\n",
      "        if w1 == w2:\n",
      "            words_bigrams.remove(item)\n",
      "    #print words_bigrams[:100]\n",
      "    words_fd = nltk.FreqDist(words_bigrams)\n",
      "    return words_fd.keys()[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Output on my collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents = GetTaggedSentences(GetSentencesFromFeynman())\n",
      "AllWords = []\n",
      "for sent in sents:\n",
      "    AllWords += sent\n",
      "result = MostFrequentBigrams(AllWords)\n",
      "for word1, word2 in result:\n",
      "    print word1, word2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Los Alamos\n",
        "Mr Feynman\n",
        "Oak Ridge\n",
        "Las Vegas\n",
        "San Francisco\n",
        "Los Angeles\n",
        "Professor Feynman\n",
        "combination wheel\n",
        "kinds things\n",
        "time idea\n",
        "time way\n",
        "Nobel Prize\n",
        "beta decay\n",
        "fragmentation knowledge\n",
        "Alibi Room\n",
        "desk drawer\n",
        "ethics equality\n",
        "lot people\n",
        "quantum theory\n",
        "telephone call\n",
        "Hans Bethe\n",
        "Mary Lou\n",
        "back hand\n",
        "back head\n",
        "guy way\n",
        "kind thing\n",
        "professor physics\n",
        "Bell Labs\n",
        "Board Education\n",
        "Building Omega\n",
        "Dresden Codex\n",
        "Feynman Mrs\n",
        "Mrs Eisenhart\n",
        "Time magazine\n",
        "cargo cult\n",
        "deck cards\n",
        "desk clerk\n",
        "drum music\n",
        "graduate student\n",
        "lot stuff\n",
        "lot trouble\n",
        "piece paper\n",
        "stars temperature\n",
        "thing time\n",
        "things time\n",
        "time problem\n",
        "time things\n",
        "top drawer\n",
        "von Neumann\n",
        "Bob Wilson\n",
        "Dirac Equation\n",
        "El Rancho\n",
        "Metaplast Corporation\n",
        "Richard Feynman\n",
        "bars dots\n",
        "book publishers\n",
        "cube root\n",
        "cult science\n",
        "curriculum commission\n",
        "door room\n",
        "drop water\n",
        "equality education\n",
        "fraternity brothers\n",
        "friend Dick\n",
        "guy couch\n",
        "guys fraternity\n",
        "hotel room\n",
        "liquid helium\n",
        "lot fun\n",
        "lot work\n",
        "lots people\n",
        "matter fact\n",
        "memories brain\n",
        "number combination\n",
        "people way\n",
        "professor Cornell\n",
        "property section\n",
        "rabbinical students\n",
        "room door\n",
        "samba music\n",
        "samba schools\n",
        "show girls\n",
        "square root\n",
        "things people\n",
        "time wife\n",
        "topless dancing\n",
        "water side\n",
        "way idea\n",
        "Academy Sciences\n",
        "Avenida Atlantica\n",
        "Center Research\n",
        "Dick Feynman\n",
        "John table\n",
        "Murray Gell-Mann\n",
        "Paul Olum\n",
        "Ph D.\n",
        "Professor Pauli\n",
        "University Carolina\n",
        "beach afternoon\n",
        "bolt slot\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Output on the brown corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = MostFrequentBigrams(GetTaggedWordsFromBrown())\n",
      "for word1, word2 in result:\n",
      "    print word1, word2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mr. Mrs.\n",
        "home runs\n",
        "U. S.\n",
        "President Kennedy\n",
        "San Francisco\n",
        "Mr. Kennedy\n",
        "Kansas City\n",
        "Premier Khrushchev\n",
        "Los Angeles\n",
        "Mantle Maris\n",
        "Mrs. John\n",
        "Mrs. Robert\n",
        "vice president\n",
        "Air Force\n",
        "El Paso\n",
        "Mr. Hawksley\n",
        "Mr. Khrushchev\n",
        "Rules Committee\n",
        "sales tax\n",
        "tax bill\n",
        "Palmer Player\n",
        "Rhode Island\n",
        "St. Louis\n",
        "farm equipment\n",
        "home rule\n",
        "home run\n",
        "toll-road bonds\n",
        "Country Club\n",
        "Morton Foods\n",
        "Mrs. William\n",
        "Secretary State\n",
        "Soviet Union\n",
        "Soviet leader\n",
        "Sunday home\n",
        "Viet Nam\n",
        "Arnold Palmer\n",
        "Austin Texas\n",
        "Emory University\n",
        "Friday night\n",
        "Fulton County\n",
        "Hong Kong\n",
        "Jr. Mrs.\n",
        "Kennedy administration\n",
        "Monday night\n",
        "Mr. Martinelli\n",
        "Mrs. Henry\n",
        "Mrs. James\n",
        "State College\n",
        "York City\n",
        "Anne Arundel\n",
        "Assemblies God\n",
        "Dallas County\n",
        "Dr. Clark\n",
        "Family Service\n",
        "Football League\n",
        "John F.\n",
        "Mr. Simpkins\n",
        "Mrs. Richard\n",
        "Notre Dame\n",
        "Peace Corps\n",
        "President Kennedy's\n",
        "Sunday sales\n",
        "Tuesday night\n",
        "York Yankees\n",
        "care plan\n",
        "cent interest\n",
        "faculty members\n",
        "gin machinery\n",
        "payroll tax\n",
        "potato chip\n",
        "race color\n",
        "rule charter\n",
        "tomorrow night\n",
        "wedding trip\n",
        "years prison\n",
        "Baltimore Ohio\n",
        "Beverly Hills\n",
        "Board Education\n",
        "Capitol Hill\n",
        "Citizens Group\n",
        "City Council\n",
        "Dr. Jenkins\n",
        "Duncan Phyfe\n",
        "Family Week\n",
        "Greer Garson\n",
        "Highway Department\n",
        "John C.\n",
        "Judge Smith\n",
        "Kennedy program\n",
        "McCormick Place\n",
        "Mickey Mantle\n",
        "Miss Garson\n",
        "Miss Mary\n",
        "Mr. Buckley\n",
        "Mr. Reama\n",
        "Mr. Wagner\n",
        "Mrs. Charles\n",
        "Mrs. Frank\n",
        "Mrs. J.\n",
        "Mrs. Marr\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Output on the mystery collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = GetMysteryText()\n",
      "sentsM = GetTaggedSentences(GetSentencesFromMystery(text))\n",
      "AllWordsM = []\n",
      "for sent in sentsM:\n",
      "    AllWordsM += sent\n",
      "result = MostFrequentBigrams(AllWordsM)\n",
      "for word1, word2 in result:\n",
      "    print word1, word2    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mln tonnes\n",
        "000 tonnes\n",
        "mln dlrs\n",
        "mln barrels\n",
        "pct sulphur\n",
        "U.S. Agriculture\n",
        "tonnes vs\n",
        "Bank Japan\n",
        "sulphur dlrs\n",
        "Agriculture Department\n",
        "dollar yen\n",
        "tonnes wheat\n",
        "vs mln\n",
        "mln bpd\n",
        "tonnes month\n",
        "vs month\n",
        "oil prices\n",
        "pct mln\n",
        "trade sources\n",
        "prices pct\n",
        "Soviet Union\n",
        "interest rates\n",
        "trade deficit\n",
        "dlrs cts\n",
        "mln hectares\n",
        "month Exports\n",
        "tonnes mln\n",
        "dlrs barrel\n",
        "pct rise\n",
        "stocks mln\n",
        "week March\n",
        "money supply\n",
        "pct February\n",
        "February pct\n",
        "Finance Minister\n",
        "cts pct\n",
        "00 mln\n",
        "bpd pct\n",
        "tonnes barley\n",
        "crop mln\n",
        "mln year\n",
        "Ecus tonne\n",
        "output mln\n",
        "pct January\n",
        "000 tons\n",
        "month 1985\n",
        "production mln\n",
        "yen dealers\n",
        "month pct\n",
        "oil companies\n",
        "pct year\n",
        "000 barrels\n",
        "Japan U.S.\n",
        "SAYS DISTILLATE\n",
        "dlrs tonne\n",
        "pct month\n",
        "tonnes market\n",
        "000 bags\n",
        "CRUDE MLN\n",
        "Paris accord\n",
        "Saudi Arabia\n",
        "barrels mln\n",
        "contract barge\n",
        "cts gallon\n",
        "currency markets\n",
        "export quotas\n",
        "gasoline stocks\n",
        "mln month\n",
        "record mln\n",
        "statement period\n",
        "tonnes maize\n",
        "000 TONNES\n",
        "Exports 1985\n",
        "Kiichi Miyazawa\n",
        "Louvre accord\n",
        "exchange rate\n",
        "fuel oil\n",
        "mln bushels\n",
        "month USDA\n",
        "rise January\n",
        "tonnes rice\n",
        "total 000\n",
        "unleaded gasoline\n",
        "wheat flour\n",
        "yen dollar\n",
        "Buenos Aires\n",
        "Crude oil\n",
        "FOB Gulf\n",
        "U.S. trade\n",
        "dlrs FOB\n",
        "dlrs mln\n",
        "exchange rates\n",
        "month Stocks\n",
        "petroleum products\n",
        "week April\n",
        "1985 mln\n",
        "BANK JAPAN\n",
        "Commodity Credit\n",
        "DISTILLATE STOCKS\n",
        "Finance Ministry\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Algorithm 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this algorithm, I am trying to extract the key phrases based on the different noun phrases which are present. Instead of extracting just the noun phrases, this gets noun phrases which are collocated. After that I am combining it with my previous algorithm to return those phrases which contain some part of the most popular bigrams.\n",
      "Procedure:\n",
      "1. Get tagged sentences from the text collection\n",
      "2. Extract all the phrases which may consist of more than one noun connected by prepositions\n",
      "3. Return only those phrases which are more than length three\n",
      "4. Using Algorithm1, return all those phrases which have the most important bigrams\n",
      "5. Returning only two phrases for each bigram so as to sifficently cover all the bigrams\n",
      "\n",
      "\n",
      "This algorithm is especially targetted at the brown corpus where it tried to identify the most relevant phrases. I've combined it with the most frequently occuring nouns to try and get the most relevant phrases. It seems to do a better job than my baseline algorithm.\n",
      "\n",
      "This could be better if there was some grouping done on the returned phrases to make it more concise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#A method which parses extended noun phrases which is a combination of noun phrases\n",
      "def ExtendedNounPhraseChunker(sent):\n",
      "    grammar = \"NP: {<CD>*(((<JJ.*>|<N.*>)+(<IN><AT>?)?(<N.*>|<CD>)*)|<N.*>)}\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    result = cp.parse(sent)\n",
      "    return result\n",
      "\n",
      "# A method which only return chunks which are of length greater than three\n",
      "def GetBigChunks(tagged_sentences):\n",
      "    chunks = []\n",
      "    bigPhrases =[]\n",
      "    chunks= ChunkASection(tagged_sentences,ExtendedNounPhraseChunker)\n",
      "    chunks = [chunk.strip() for chunk in chunks]\n",
      "    chunks = [chunk for chunk in chunks if len(chunk.split())>3]\n",
      "    return chunks\n",
      "\n",
      "#A method which return all the phrases which contains the most frequent bigrams\n",
      "#It takes tagged sentences as the first parameter and tagged words as the second parameter\n",
      "def GetMostUsedNounPhrases(sents,words):\n",
      "    bigChunks = GetBigChunks(sents)\n",
      "    freqBi = MostFrequentBigrams(AllWords)\n",
      "    my_set_of_bigchunks = []\n",
      "    for (n1,n2) in freqBi[:60]:\n",
      "        my_set_of_bigchunks += [chunk for chunk in bigChunks if n1 in chunk or n2 in chunk][:2]\n",
      "    return my_set_of_bigchunks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Output on my collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents = GetTaggedSentences(GetSentencesFromFeynman())\n",
      "AllWords = []\n",
      "for sent in sents:\n",
      "    AllWords += sent\n",
      "result = GetMostUsedNounPhrases(sents,AllWords)\n",
      "for value in result:\n",
      "    print value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: parsing empty text\n",
        "Warning: parsing empty text\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text\n",
        "Warning: parsing empty text\n",
        "Los Alamos in April 1943"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Reminiscences of Los Alamos\n",
        "Curious Character by Richard P. Feynman\n",
        "memoirs of Richard Feynman\n",
        "people in Oak Ridge\n",
        "somewhere-usually in Las Vegas\n",
        "life in Las Vegas\n",
        "Annual Santa Barbara Lectures on Science\n",
        "California at Santa Barbara\n",
        "Los Alamos in April 1943\n",
        "Reminiscences of Los Alamos\n",
        "Curious Character by Richard P. Feynman\n",
        "memoirs of Richard Feynman\n",
        "different combinations of switches\n",
        "eight-inch diameter gear wheel\n",
        "lot of subsidiary things\n",
        "new kinds of plastics\n",
        "time for a printer\n",
        "s times i times n times f\n",
        "time for a printer\n",
        "s times i times n times f\n",
        "account of the Nobel Prize\n",
        "ceremony for the Nobel-Prize-winners\n",
        "right laws of beta decay\n",
        "new possibilities for beta decay theory\n",
        "fragmentation of knowledge \"\n",
        "fragmentation of knowledge \"\n",
        "Alibi Room about ten years\n",
        "00 in Room D102\n",
        "top of the desk\n",
        "top of the desk\n",
        "little bit-something about ethics\n",
        "\" ethics of equality\n",
        "whole lot of knives\n",
        "lot at Palmer Laboratory\n",
        "theory about the clouds\n",
        "idea of a theory\n",
        "book by the telephone\n",
        "long distance call from\n",
        "group leader under Bethe\n",
        "Hans Bethe at General Electric\n",
        "\" Mo teco TIEto capeto TUtto ... \" Loud\n",
        "Mary Lou at Cornell\n",
        "background material in one sketch\n",
        "handyman at the hotel\n",
        "background material in one sketch\n",
        "head of the team\n",
        "guy on the radio\n",
        "guys from the Phi Beta Delta fraternity\n",
        "kind of coffee cake\n",
        "kind of potato salad\n",
        "physics problems with me-I\n",
        "professor of \" French littrachaw \"\n",
        "Electrical Testing Labs in\n",
        "time on the State Board\n",
        "recommendations for the Board\n",
        "copy of the Dresden Codex\n",
        "beautiful color reproductions of the Dresden Codex\n",
        "Curious Character by Richard P. Feynman\n",
        "memoirs of Richard Feynman\n",
        "name in Time magazine\n",
        "guy from Time magazine\n",
        "difficult thing in the\n",
        "rid of the difficulty\n",
        "small deck of ten cards\n",
        "deck of fifty cards\n",
        "top of the desk\n",
        "top of the desk\n",
        "beat of a drum\n",
        "new music for the Carnaval\n",
        "introduction to the graduate \" College \"\n",
        "dean of the graduate school\n",
        "stuff from the tables\n",
        "stuff ready for desserts\n",
        "trouble with the radio\n",
        "whole lot of knives\n",
        "pieces of bell wire\n",
        "switchboard behind a piece\n",
        "two different populations of stars\n",
        "temperature of four thousand degrees\n",
        "time for a printer\n",
        "s times i times n times f\n",
        "time for a printer\n",
        "s times i times n times f\n",
        "time for a printer\n",
        "problem on the blackboard\n",
        "time for a printer\n",
        "s times i times n times f\n",
        "black top of the demonstration bench\n",
        "spark terminals at the top\n",
        "\" Johnny von Neumann\n",
        "result of von Neumann's advice\n",
        "Bob Wilson's house for a weekend\n",
        "Dirac Equation in electrodynamics\n",
        "Electrical Testing Labs in\n",
        "Hans Bethe at General Electric\n",
        "Chief Research Chemist of the Metaplast Corporation\n",
        "chief research chemist at the Metaplast Corporation\n",
        "Curious Character by Richard P. Feynman\n",
        "memoirs of Richard Feynman\n",
        "people in the bars\n",
        "meeting people in bars\n",
        "standard demonstration in the book\n",
        "book by the telephone\n",
        "cube root of 2Vi\n",
        "cube roots on the Marchant\n",
        "difficult thing in the\n",
        "closest thing to science\n",
        "members of the commission\n",
        "curriculum commission to the Board\n",
        "little room in the back\n",
        "Playmore Ballroom two ballrooms\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Output on brown corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = GetMostUsedNounPhrases(GetTaggedSentencesFromBrown(),GetTaggedWordsFromBrown())\n",
      "for value in result:\n",
      "    print value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "round of the Los Angeles open\n",
        "inviting target in Los Angeles' Wrigley Field Jr.\n",
        "Mrs. J. M. Cheshire of Griffin\n",
        "Mr. Rusk's analysis of the\n",
        "Three positions on the Oak Lodge Water district board\n",
        "Oak Park Arms hotel\n",
        "planes to Las Vegas\n",
        "popular act in Vegas\n",
        "ex-gambler from San Antonio\n",
        "Sen. Louis Crump of San Saba\n",
        "round of the Los Angeles open\n",
        "inviting target in Los Angeles' Wrigley Field Jr.\n",
        "whole wheels of the agency\n",
        "favorite color combination along\n",
        "sponsor of the poll idea\n",
        "guilt at the time\n",
        "State Highway Department public relations director\n",
        "$100 million highway bond issue\n",
        "1958 Nobel Prize in medicine\n",
        "knowledge in the program\n",
        "fragmentation of the Congo\n",
        "Tuesday in the Sam Houston Room\n",
        "East Room of the\n",
        "different idea on the ethics\n",
        "referendum on the April 4 ballot\n",
        "Wise County hamlet of 250 people\n",
        "anonymous midnight phone calls\n",
        "telephone yesterday with Representative Charles A. Buckley\n",
        "Sen. Louis Crump of San Saba\n",
        "Miss Mary R. Grant\n",
        "swipe at the State Welfare Department's handling\n",
        "setbacks for the West\n",
        "setbacks for the West\n",
        "present city CD head\n",
        "State Highway Department public relations director\n",
        "$100 million highway bond issue\n",
        "kind of taxes Texans\n",
        "rekindling of NATO realization\n",
        "associate professor of education\n",
        "disclosure by Charles Bellows\n",
        "Education degree from the University\n",
        "member of the State Board\n",
        "president of Alpha Tau Omega\n",
        "chairman of the Music Center Building Fund Committee\n",
        "Mrs. J. M. Cheshire of Griffin\n",
        "appointment of Mrs. Harriet Copeland Greenfield\n",
        "Mrs. J. M. Cheshire of Griffin\n",
        "appointment of Mrs. Harriet Copeland Greenfield\n",
        "yesterday's New York Times\n",
        "New York Times from\n",
        "difficult problems in the months\n",
        "difficult year in 1961\n",
        "deputy city clerk of\n",
        "clerk of the board\n",
        "Jack Kelly on drums\n",
        "musical director of the San Francisco Symphony\n",
        "deaf students in the\n",
        "graduate of Portland University\n",
        "referendum on the April 4 ballot\n",
        "non-partisan ballot for posts\n",
        "referendum on the April 4 ballot\n",
        "non-partisan ballot for posts\n",
        "end to paper ballots\n",
        "reader of the Boston newspapers\n",
        "scholastic stars in football\n",
        "guilt at the time\n",
        "timely political consultation within the alliance\n",
        "guilt at the time\n",
        "timely political consultation within the alliance\n",
        "guilt at the time\n",
        "timely political consultation within the alliance\n",
        "guilt at the time\n",
        "timely political consultation within the alliance\n",
        "stop to the piracy\n",
        "Frank Cipriani's single under Shortstop Jerry Adair's glove\n",
        "Alfred Neumann of Beaumont\n",
        "Bobby Waters of Sylvania\n",
        "long pass by quarterback Bob McNaughton\n",
        "work on the El\n",
        "Miss Judith Ellen Gay\n",
        "study by Johns-Manville Corporation\n",
        "president of the Byer-Rolnick Hat Corporation\n",
        "Vice-President Richard M. Nixon in Detroit\n",
        "remark by Richard J. Hughes\n",
        "play in the book\n",
        "glamorous record on the books\n",
        "wider grassroots support for quality library service\n",
        "difficult problems in the months\n",
        "difficult year in 1961\n",
        "possible election of a nine member charter commission\n",
        "candidates for the charter commission\n",
        "hotels with 1000 rooms\n",
        "final indoor meet of the season\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Output on the mystery collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = GetMysteryText()\n",
      "sents = GetTaggedSentences(GetSentencesFromMystery(text))\n",
      "AllWords = []\n",
      "for sent in sents:\n",
      "    AllWords += sent\n",
      "result = GetMostUsedNounPhrases(sents,AllWords)\n",
      "for value in result:\n",
      "    print value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "oil worth about 10 mln U.S. Dlrs\n",
        "6 mln barrels per day\n",
        "000 TONS OF DIESEL FROM USSR Bangladesh\n",
        "000 barrels in the week\n",
        "7 pct sulphur to 21 dlrs\n",
        "7 pct sulphur to 21 dlrs\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "6 mln barrels per day\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "U.S. Stockbuilding for winter\n",
        "000 tonnes per annum\n",
        "000 tonnes of asbestos fibre\n",
        "\" A Japanese oil trader\n",
        "senior energy economist with Bankers Trust Corp\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "Agriculture Minister Denis Bra Kanon\n",
        "SRI LANKA GETS USDA APPROVAL FOR WHEAT PRICE Food Department officials\n",
        "145 yen per litre\n",
        "small amount of dollars\n",
        "000 tonnes per annum\n",
        "000 tonnes of asbestos fibre\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "6 mln barrels per day\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "6 mln barrels per day\n",
        "month to repair Ecuador's\n",
        "000 tonnes per annum\n",
        "month to repair Ecuador's\n",
        "months of the government's Cruzado Plan price\n",
        "cargo prices for number six fuel\n",
        "prices for one pct sulphur\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "European crude oil trader\n",
        "\" A Japanese oil trader\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "high speed diesel oil from the Soviet Union\n",
        "return to the Soviet Union\n",
        "interest payments on part\n",
        "Shell's interest in 39\n",
        "European crude oil trader\n",
        "\" A Japanese oil trader\n",
        "heavy fuel 50 cts\n",
        "7 pct sulphur to 21 dlrs\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "6 mln barrels per day\n",
        "month to repair Ecuador's\n",
        "months of the government's Cruzado Plan price\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "6 mln barrels per day\n",
        "7 pct sulphur to 21 dlrs\n",
        "7 pct sulphur to 21 dlrs\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "6 mln barrels per day\n",
        "000 barrels in the week\n",
        "refinery runs in the week\n",
        "supply shortages under the production quota guideline\n",
        "grave consequences for the supply situation\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "Finance Minister Cleopa Msuya\n",
        "Finance Minister Cleopa Msuya\n",
        "heavy fuel 50 cts\n",
        "5 pct sulphur fuel to 21\n",
        "000 TONS OF DIESEL FROM USSR Bangladesh\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "000 tonnes per annum\n",
        "000 tonnes of asbestos fibre\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "6 mln barrels per day\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "financial year 1987 8\n",
        "000 tonnes per annum\n",
        "000 tonnes of asbestos fibre\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "crude oil output to 16\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "000 TONS OF DIESEL FROM USSR Bangladesh\n",
        "000 barrels in the week\n",
        "month to repair Ecuador's\n",
        "months of the government's Cruzado Plan price\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "6 mln barrels per day\n",
        "145 yen per litre\n",
        "33 yen against 145\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "SINGAPORE OIL COMPANIES TO SET OWN PUMP PRICES Singapore oil companies\n",
        "changes for the oil companies\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "000 TONS OF DIESEL FROM USSR Bangladesh\n",
        "6 mln barrels per day\n",
        "oil worth about 10 mln U.S. Dlrs\n",
        "\" A Japanese oil trader\n",
        "EIA SAYS DISTILLATE STOCKS UNCHANGED\n",
        "3 MLN EIA SAYS DISTILLATE STOCKS UNCHANGED\n",
        "7 pct sulphur to 21 dlrs\n",
        "7 pct sulphur to 21 dlrs\n",
        "5 pct sulphur fuel to 21\n",
        "7 pct sulphur to 21 dlrs\n",
        "market respect for the cartel\n",
        "utilities market at the expense\n",
        "000 TONS OF DIESEL FROM USSR Bangladesh\n",
        "000 barrels in the week\n",
        "3 MLN EIA SAYS DISTILLATE STOCKS UNCHANGED\n",
        "3 MLN EIA SAYS DISTILLATE STOCKS UNCHANGED IN WEEK Distillate fuel stocks\n",
        "prospects for an accord\n",
        "four-year beef accord next March 31\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Algorithm 3"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this algorithm, I am trying to produce a mapping of verbs to nouns phrases. For 5 verbs, which I am picking from a list of most frequent verbs, I am producing the noun phrases most commonly associated with it.\n",
      "\n",
      "Procedure\n",
      "1. Get tagged text from collection\n",
      "2. Get all the verbs in the collection\n",
      "3. Find the forty most frequent verbs\n",
      "4. After skipping some of the most frequent verbs, whcih tend to be less important, pcik a subset of the verbs\n",
      "5. Get all sentences with those verbs\n",
      "6. Run a noun  phrase chunker on those sentences to get the noun phrases most associated with the verb\n",
      "\n",
      "This algorithm is relevant, especially for my collection, as it covers the life of Richard Feynman. It is very interesting to see the various activities which Feynman performed, and the output of those actions. \n",
      "\n",
      "This algorithm could be better improved by considering a better selection of verbs and maybe a wider set of verbs and improving the noun phrases related to that verb."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "#This method return all the noun phrases associated with a set of verbs\n",
      "#it takes tagged sentences and non-tagged sentences as parameters\n",
      "def GetNounPhrasesAssociatedWithImportantVerbs(tagged_sents,sents):\n",
      "    verbs = ChunkASection(tagged_sents,VerbChunker)\n",
      "    verb_fd = nltk.FreqDist(verbs)\n",
      "    # verb_fd.plot(40,cumulative=False)\n",
      "    importantverbs = verb_fd.keys()[10:15]\n",
      "    sentswithverbs ={}\n",
      "    for verb in importantverbs:\n",
      "        sentswithverbs[verb.strip()] = GetTaggedSentences(GetSentencesWith(sents,verb.strip()))\n",
      "    nounPhrasesDict={}\n",
      "    for key in sentswithverbs.keys():\n",
      "        nounPhrasesDict[key]= nltk.FreqDist(ChunkASection(sentswithverbs[key],NounPhraseChunker)).keys()[:40]\n",
      "    return nounPhrasesDict\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Output on my text collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents = GetSentencesFromFeynman()\n",
      "result = GetNounPhrasesAssociatedWithImportantVerbs(GetTaggedSentences(sents),sents)\n",
      "df = pd.DataFrame(result)\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: parsing empty text\n",
        "Warning: parsing empty text\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text\n",
        "Warning: parsing empty text\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>looked</th>\n",
        "      <th>made</th>\n",
        "      <th>started</th>\n",
        "      <th>took</th>\n",
        "      <th>worked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>           \" </td>\n",
        "      <td>            \" </td>\n",
        "      <td>                    \" </td>\n",
        "      <td>              \" </td>\n",
        "      <td>            \" </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>        good </td>\n",
        "      <td>       people </td>\n",
        "      <td>                  guy </td>\n",
        "      <td>           room </td>\n",
        "      <td>         time </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>        back </td>\n",
        "      <td>          way </td>\n",
        "      <td>              Cornell </td>\n",
        "      <td>           time </td>\n",
        "      <td>       things </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>         lot </td>\n",
        "      <td>      mistake </td>\n",
        "      <td>         conversation </td>\n",
        "      <td>           door </td>\n",
        "      <td>   Los Alamos </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>        time </td>\n",
        "      <td>      physics </td>\n",
        "      <td>                 time </td>\n",
        "      <td>           care </td>\n",
        "      <td>          guy </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>         big </td>\n",
        "      <td>        thing </td>\n",
        "      <td>              Caltech </td>\n",
        "      <td>            way </td>\n",
        "      <td>        night </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>        book </td>\n",
        "      <td>    beginning </td>\n",
        "      <td>                  bus </td>\n",
        "      <td>           Coke </td>\n",
        "      <td>       theory </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>       books </td>\n",
        "      <td>         book </td>\n",
        "      <td>               people </td>\n",
        "      <td>           able </td>\n",
        "      <td>          way </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>        hand </td>\n",
        "      <td>          end </td>\n",
        "      <td>              problem </td>\n",
        "      <td>        bottles </td>\n",
        "      <td>         able </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>     reports </td>\n",
        "      <td>         girl </td>\n",
        "      <td>           Los Alamos </td>\n",
        "      <td>       document </td>\n",
        "      <td>         bomb </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>        room </td>\n",
        "      <td>          guy </td>\n",
        "      <td>    Manhattan Project </td>\n",
        "      <td>           fire </td>\n",
        "      <td>   conference </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>      window </td>\n",
        "      <td>         kind </td>\n",
        "      <td>             One time </td>\n",
        "      <td>           guys </td>\n",
        "      <td>   experiment </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> Albuquerque </td>\n",
        "      <td>          lot </td>\n",
        "      <td>           Portuguese </td>\n",
        "      <td>           hand </td>\n",
        "      <td>          lot </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>     Emperor </td>\n",
        "      <td>         mind </td>\n",
        "      <td>            Princeton </td>\n",
        "      <td>         office </td>\n",
        "      <td>     neutrons </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>    New York </td>\n",
        "      <td>     students </td>\n",
        "      <td>              Spanish </td>\n",
        "      <td>          scene </td>\n",
        "      <td>      Chicago </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>  Paramecium </td>\n",
        "      <td>       theory </td>\n",
        "      <td>                 band </td>\n",
        "      <td>           year </td>\n",
        "      <td>    Princeton </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>        able </td>\n",
        "      <td>       things </td>\n",
        "      <td>                 bomb </td>\n",
        "      <td>          ... \" </td>\n",
        "      <td>     basement </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>         bad </td>\n",
        "      <td>         time </td>\n",
        "      <td>                 book </td>\n",
        "      <td>      Princeton </td>\n",
        "      <td>         code </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>     cabinet </td>\n",
        "      <td>         able </td>\n",
        "      <td>             cabinets </td>\n",
        "      <td>       basement </td>\n",
        "      <td>    documents </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>         car </td>\n",
        "      <td>  arrangement </td>\n",
        "      <td>                 cell </td>\n",
        "      <td>       bathroom </td>\n",
        "      <td>         easy </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>   dormitory </td>\n",
        "      <td> arrangements </td>\n",
        "      <td>                class </td>\n",
        "      <td>           book </td>\n",
        "      <td>       father </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>        drop </td>\n",
        "      <td>    discovery </td>\n",
        "      <td>                 date </td>\n",
        "      <td>          books </td>\n",
        "      <td> five degrees </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>      friend </td>\n",
        "      <td>         door </td>\n",
        "      <td>                 door </td>\n",
        "      <td>        cabinet </td>\n",
        "      <td>        group </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>         guy </td>\n",
        "      <td>         fact </td>\n",
        "      <td>          experiments </td>\n",
        "      <td> certain amount </td>\n",
        "      <td>         guys </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>        idea </td>\n",
        "      <td>         idea </td>\n",
        "      <td>                 eyes </td>\n",
        "      <td>         course </td>\n",
        "      <td>         hard </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>        keys </td>\n",
        "      <td>         lady </td>\n",
        "      <td>          good reason </td>\n",
        "      <td>            day </td>\n",
        "      <td>  interesting </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>        kind </td>\n",
        "      <td>         lock </td>\n",
        "      <td>                 idea </td>\n",
        "      <td>   five minutes </td>\n",
        "      <td>       lights </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>        left </td>\n",
        "      <td>          man </td>\n",
        "      <td>               leader </td>\n",
        "      <td>     fraternity </td>\n",
        "      <td>     machines </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>        list </td>\n",
        "      <td>    molecules </td>\n",
        "      <td> little wooden tables </td>\n",
        "      <td>         friend </td>\n",
        "      <td>   mysterious </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>      little </td>\n",
        "      <td> observations </td>\n",
        "      <td>                  lot </td>\n",
        "      <td>           girl </td>\n",
        "      <td>      picture </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td> little hole </td>\n",
        "      <td>        plate </td>\n",
        "      <td>             material </td>\n",
        "      <td>           good </td>\n",
        "      <td>     plastics </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td>       lousy </td>\n",
        "      <td>      rhythms </td>\n",
        "      <td>              meeting </td>\n",
        "      <td>           hour </td>\n",
        "      <td>      problem </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td>        mail </td>\n",
        "      <td>      smaller </td>\n",
        "      <td>                model </td>\n",
        "      <td>           idea </td>\n",
        "      <td>      program </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td>     morning </td>\n",
        "      <td>        table </td>\n",
        "      <td>                night </td>\n",
        "      <td>        lessons </td>\n",
        "      <td>       public </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>    pictures </td>\n",
        "      <td>         talk </td>\n",
        "      <td>              numbers </td>\n",
        "      <td>          light </td>\n",
        "      <td>    ribosomes </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>    question </td>\n",
        "      <td>         tape </td>\n",
        "      <td>               others </td>\n",
        "      <td>     little bit </td>\n",
        "      <td>        right </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td>       stage </td>\n",
        "      <td>        theme </td>\n",
        "      <td>             pictures </td>\n",
        "      <td>           lock </td>\n",
        "      <td>        stuff </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>         tau </td>\n",
        "      <td>       weight </td>\n",
        "      <td>                place </td>\n",
        "      <td>       magazine </td>\n",
        "      <td>         such </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td>       water </td>\n",
        "      <td>        wheel </td>\n",
        "      <td>             pleasure </td>\n",
        "      <td>          money </td>\n",
        "      <td>      uranium </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td>         way </td>\n",
        "      <td>   Los Alamos </td>\n",
        "      <td>                 room </td>\n",
        "      <td>          night </td>\n",
        "      <td>          war </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "          looked           made                started             took  \\\n",
        "0             \"              \"                      \"                \"    \n",
        "1          good         people                    guy             room    \n",
        "2          back            way                Cornell             time    \n",
        "3           lot        mistake           conversation             door    \n",
        "4          time        physics                   time             care    \n",
        "5           big          thing                Caltech              way    \n",
        "6          book      beginning                    bus             Coke    \n",
        "7         books           book                 people             able    \n",
        "8          hand            end                problem          bottles    \n",
        "9       reports           girl             Los Alamos         document    \n",
        "10         room            guy      Manhattan Project             fire    \n",
        "11       window           kind               One time             guys    \n",
        "12  Albuquerque            lot             Portuguese             hand    \n",
        "13      Emperor           mind              Princeton           office    \n",
        "14     New York       students                Spanish            scene    \n",
        "15   Paramecium         theory                   band             year    \n",
        "16         able         things                   bomb            ... \"    \n",
        "17          bad           time                   book        Princeton    \n",
        "18      cabinet           able               cabinets         basement    \n",
        "19          car    arrangement                   cell         bathroom    \n",
        "20    dormitory   arrangements                  class             book    \n",
        "21         drop      discovery                   date            books    \n",
        "22       friend           door                   door          cabinet    \n",
        "23          guy           fact            experiments   certain amount    \n",
        "24         idea           idea                   eyes           course    \n",
        "25         keys           lady            good reason              day    \n",
        "26         kind           lock                   idea     five minutes    \n",
        "27         left            man                 leader       fraternity    \n",
        "28         list      molecules   little wooden tables           friend    \n",
        "29       little   observations                    lot             girl    \n",
        "30  little hole          plate               material             good    \n",
        "31        lousy        rhythms                meeting             hour    \n",
        "32         mail        smaller                  model             idea    \n",
        "33      morning          table                  night          lessons    \n",
        "34     pictures           talk                numbers            light    \n",
        "35     question           tape                 others       little bit    \n",
        "36        stage          theme               pictures             lock    \n",
        "37          tau         weight                  place         magazine    \n",
        "38        water          wheel               pleasure            money    \n",
        "39          way     Los Alamos                   room            night    \n",
        "\n",
        "           worked  \n",
        "0              \"   \n",
        "1           time   \n",
        "2         things   \n",
        "3     Los Alamos   \n",
        "4            guy   \n",
        "5          night   \n",
        "6         theory   \n",
        "7            way   \n",
        "8           able   \n",
        "9           bomb   \n",
        "10    conference   \n",
        "11    experiment   \n",
        "12           lot   \n",
        "13      neutrons   \n",
        "14       Chicago   \n",
        "15     Princeton   \n",
        "16      basement   \n",
        "17          code   \n",
        "18     documents   \n",
        "19          easy   \n",
        "20        father   \n",
        "21  five degrees   \n",
        "22         group   \n",
        "23          guys   \n",
        "24          hard   \n",
        "25   interesting   \n",
        "26        lights   \n",
        "27      machines   \n",
        "28    mysterious   \n",
        "29       picture   \n",
        "30      plastics   \n",
        "31       problem   \n",
        "32       program   \n",
        "33        public   \n",
        "34     ribosomes   \n",
        "35         right   \n",
        "36         stuff   \n",
        "37          such   \n",
        "38       uranium   \n",
        "39           war   "
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Output on the brown corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown_sentences = [\" \".join(sent) for sent in GetSentencesFromBrown()]\n",
      "result2 = GetNounPhrasesAssociatedWithImportantVerbs(GetTaggedSentencesFromBrown(),brown_sentences)\n",
      "df2 = pd.DataFrame(result2)\n",
      "df2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>announced</th>\n",
        "      <th>asked</th>\n",
        "      <th>became</th>\n",
        "      <th>called</th>\n",
        "      <th>gave</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>                                     Mrs </td>\n",
        "      <td>                                       ` ` </td>\n",
        "      <td>                                      ` ` </td>\n",
        "      <td>                            industry </td>\n",
        "      <td>                      Laos </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>                               yesterday </td>\n",
        "      <td>                                     Paris </td>\n",
        "      <td>                               13 primary </td>\n",
        "      <td>                          Government </td>\n",
        "      <td>                    States </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>                                  Friday </td>\n",
        "      <td>                                 President </td>\n",
        "      <td>             Birmingham Repertory Company </td>\n",
        "      <td>                                  Mr </td>\n",
        "      <td>                  one time </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>                             appointment </td>\n",
        "      <td>                                     board </td>\n",
        "      <td>                                  British </td>\n",
        "      <td>                           President </td>\n",
        "      <td>                   trouble </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>                               president </td>\n",
        "      <td>                                    family </td>\n",
        "      <td>                                  Chicago </td>\n",
        "      <td>                           Secretary </td>\n",
        "      <td>                       065 </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>                                  Monday </td>\n",
        "      <td>                                      jury </td>\n",
        "      <td>  Christian Anti-Communist Crusade school </td>\n",
        "      <td>                                able </td>\n",
        "      <td>                  1-0 lead </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>                                  Russia </td>\n",
        "      <td>                                   members </td>\n",
        "      <td>                Communist Chinese demands </td>\n",
        "      <td>                                case </td>\n",
        "      <td>                 1961 shot </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>                                Saturday </td>\n",
        "      <td>                                  question </td>\n",
        "      <td>                        Communist leaders </td>\n",
        "      <td>                             efforts </td>\n",
        "      <td>      3-game total offense </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>                                Trustees </td>\n",
        "      <td>                                    report </td>\n",
        "      <td>                     Communist operations </td>\n",
        "      <td>                             opinion </td>\n",
        "      <td>         380-foot home run </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>                               Wednesday </td>\n",
        "      <td>                             $46.7 billion </td>\n",
        "      <td>                          Communist state </td>\n",
        "      <td>                              police </td>\n",
        "      <td>                 512 yards </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>                                     ` ` </td>\n",
        "      <td>                              $754 million </td>\n",
        "      <td>                                Confusion </td>\n",
        "      <td>                             problem </td>\n",
        "      <td>            545-yard spree </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>                               candidate </td>\n",
        "      <td>             10 million dollar ` ` initial </td>\n",
        "      <td>                                   Dunkel </td>\n",
        "      <td>               racial discrimination </td>\n",
        "      <td> 6-foot-3-inch 158-pounder </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>                                     day </td>\n",
        "      <td>                                15 meeting </td>\n",
        "      <td>                                   French </td>\n",
        "      <td>                              report </td>\n",
        "      <td>                       A's </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>                              executions </td>\n",
        "      <td>                         20 million dollar </td>\n",
        "      <td>                                   Friday </td>\n",
        "      <td>                               today </td>\n",
        "      <td>                 Athletics </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>                                    help </td>\n",
        "      <td>                               50 millions </td>\n",
        "      <td>                                   Geneva </td>\n",
        "      <td>                          $100 check </td>\n",
        "      <td>               Auntie Mame </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>                                   place </td>\n",
        "      <td>                                7 furlongs </td>\n",
        "      <td>                            German market </td>\n",
        "      <td>              10 witnesses yesterday </td>\n",
        "      <td>                  Beardens </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>                                    race </td>\n",
        "      <td>                             Alan Clements </td>\n",
        "      <td>                             German pilot </td>\n",
        "      <td>                          102 joints </td>\n",
        "      <td>               Bill Tuttle </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>                                   today </td>\n",
        "      <td> Anne Arundel county school superintendent </td>\n",
        "      <td>                                  Germany </td>\n",
        "      <td>                           145 yards </td>\n",
        "      <td>                     Birds </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>                                     $28 </td>\n",
        "      <td>                                      B Aj </td>\n",
        "      <td>                               Indo-China </td>\n",
        "      <td>                            26 times </td>\n",
        "      <td>               Bob Allison </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>                                      $9 </td>\n",
        "      <td>                                   Bellows </td>\n",
        "      <td>                            Ivan Allen Jr </td>\n",
        "      <td>                      ADC dependency </td>\n",
        "      <td>                   British </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>                                     000 </td>\n",
        "      <td>                                     Bible </td>\n",
        "      <td>                                      Jim </td>\n",
        "      <td>                           Americans </td>\n",
        "      <td>                  Broadway </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>                                      01 </td>\n",
        "      <td>                                     Board </td>\n",
        "      <td>                              Judge Smith </td>\n",
        "      <td>                       Arab Republic </td>\n",
        "      <td>                 Cardinals </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>                      10-o'clock scholar </td>\n",
        "      <td>                                Communists </td>\n",
        "      <td>                                     Laos </td>\n",
        "      <td>                    Attorney General </td>\n",
        "      <td> Communist Chinese demands </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>                               100 years </td>\n",
        "      <td>                                  Congress </td>\n",
        "      <td>                              Los Angeles </td>\n",
        "      <td>                     Barbara Borland </td>\n",
        "      <td>      Communist operations </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>                              13 primary </td>\n",
        "      <td>                                 Democrats </td>\n",
        "      <td>                                  Lumumba </td>\n",
        "      <td>                      Belgian troops </td>\n",
        "      <td>           Communist state </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>                        130-year history </td>\n",
        "      <td>                                 Education </td>\n",
        "      <td>                              Macwhyte Co </td>\n",
        "      <td>                           Ben Stein </td>\n",
        "      <td>                Communists </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td> 1961 Columbus Day Celebration Committee </td>\n",
        "      <td>                      Fair Dealer Humphrey </td>\n",
        "      <td>                             Marin county </td>\n",
        "      <td>                            Bourcier </td>\n",
        "      <td>                     Corps </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>                      24 earned-run mark </td>\n",
        "      <td>                          Friday's letters </td>\n",
        "      <td>                         Mayor Hartsfield </td>\n",
        "      <td>                         Buchheister </td>\n",
        "      <td>                      D.C. </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>                            25-foot putt </td>\n",
        "      <td>                              Garden Fresh </td>\n",
        "      <td>                                    Miami </td>\n",
        "      <td>                           Composite </td>\n",
        "      <td>      Field's long service </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>                        330 Woodland Ave </td>\n",
        "      <td>                     Georgia's congressmen </td>\n",
        "      <td>                                      Mrs </td>\n",
        "      <td>                           Congolese </td>\n",
        "      <td>   Frank Cipriani's single </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td>                                     AID </td>\n",
        "      <td>                         Henry Hall Wilson </td>\n",
        "      <td>                 National Audubon Society </td>\n",
        "      <td>                Congolese Government </td>\n",
        "      <td>                    French </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td>                  Allen Lehman McCluskey </td>\n",
        "      <td>                                    Holmes </td>\n",
        "      <td>                           North Viet Nam </td>\n",
        "      <td>  County Supervisor Weldon R. Sheets </td>\n",
        "      <td>                    Geneva </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td>                             Appointment </td>\n",
        "      <td>                                    Hughes </td>\n",
        "      <td>               Northwest district manager </td>\n",
        "      <td>                  Cuban tractor plan </td>\n",
        "      <td>          Harmon Killebrew </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td>                        Attorney General </td>\n",
        "      <td>                                       ICC </td>\n",
        "      <td>                                       P. </td>\n",
        "      <td>                                  D. </td>\n",
        "      <td>                      Hyde </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>                               Baltimore </td>\n",
        "      <td>                       Jack Lowe's program </td>\n",
        "      <td>                                   Police </td>\n",
        "      <td> Democratic gubernatorial nomination </td>\n",
        "      <td>                Indo-China </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>                                Belgians </td>\n",
        "      <td>                       Jockey Philip Grimm </td>\n",
        "      <td>                       President Kasavubu </td>\n",
        "      <td>                  Desmond D. Connall </td>\n",
        "      <td>                Jim Landis </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td>                              Bob Gibson </td>\n",
        "      <td>                                Judge Cash </td>\n",
        "      <td> Reed Rogers Da Fonta Wild Life Sanctuary </td>\n",
        "      <td>                             Detroit </td>\n",
        "      <td>                    Keegan </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>                                 Britain </td>\n",
        "      <td>                             Judge Parsons </td>\n",
        "      <td>                                  Russian </td>\n",
        "      <td>                   Drexel collection </td>\n",
        "      <td>   Ku Klux Klan membership </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td>                         Britain's plans </td>\n",
        "      <td>                                   Kennedy </td>\n",
        "      <td>                     San Francisco Giants </td>\n",
        "      <td>                           Education </td>\n",
        "      <td>                 Longhorns </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td>            British navy's chief adviser </td>\n",
        "      <td>                    Kennedy administration </td>\n",
        "      <td>                                     Sept </td>\n",
        "      <td>                               Egypt </td>\n",
        "      <td>  Lovely Thrush Annamorena </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "                                   announced  \\\n",
        "0                                       Mrs    \n",
        "1                                 yesterday    \n",
        "2                                    Friday    \n",
        "3                               appointment    \n",
        "4                                 president    \n",
        "5                                    Monday    \n",
        "6                                    Russia    \n",
        "7                                  Saturday    \n",
        "8                                  Trustees    \n",
        "9                                 Wednesday    \n",
        "10                                      ` `    \n",
        "11                                candidate    \n",
        "12                                      day    \n",
        "13                               executions    \n",
        "14                                     help    \n",
        "15                                    place    \n",
        "16                                     race    \n",
        "17                                    today    \n",
        "18                                      $28    \n",
        "19                                       $9    \n",
        "20                                      000    \n",
        "21                                       01    \n",
        "22                       10-o'clock scholar    \n",
        "23                                100 years    \n",
        "24                               13 primary    \n",
        "25                         130-year history    \n",
        "26  1961 Columbus Day Celebration Committee    \n",
        "27                       24 earned-run mark    \n",
        "28                             25-foot putt    \n",
        "29                         330 Woodland Ave    \n",
        "30                                      AID    \n",
        "31                   Allen Lehman McCluskey    \n",
        "32                              Appointment    \n",
        "33                         Attorney General    \n",
        "34                                Baltimore    \n",
        "35                                 Belgians    \n",
        "36                               Bob Gibson    \n",
        "37                                  Britain    \n",
        "38                          Britain's plans    \n",
        "39             British navy's chief adviser    \n",
        "\n",
        "                                         asked  \\\n",
        "0                                         ` `    \n",
        "1                                       Paris    \n",
        "2                                   President    \n",
        "3                                       board    \n",
        "4                                      family    \n",
        "5                                        jury    \n",
        "6                                     members    \n",
        "7                                    question    \n",
        "8                                      report    \n",
        "9                               $46.7 billion    \n",
        "10                               $754 million    \n",
        "11              10 million dollar ` ` initial    \n",
        "12                                 15 meeting    \n",
        "13                          20 million dollar    \n",
        "14                                50 millions    \n",
        "15                                 7 furlongs    \n",
        "16                              Alan Clements    \n",
        "17  Anne Arundel county school superintendent    \n",
        "18                                       B Aj    \n",
        "19                                    Bellows    \n",
        "20                                      Bible    \n",
        "21                                      Board    \n",
        "22                                 Communists    \n",
        "23                                   Congress    \n",
        "24                                  Democrats    \n",
        "25                                  Education    \n",
        "26                       Fair Dealer Humphrey    \n",
        "27                           Friday's letters    \n",
        "28                               Garden Fresh    \n",
        "29                      Georgia's congressmen    \n",
        "30                          Henry Hall Wilson    \n",
        "31                                     Holmes    \n",
        "32                                     Hughes    \n",
        "33                                        ICC    \n",
        "34                        Jack Lowe's program    \n",
        "35                        Jockey Philip Grimm    \n",
        "36                                 Judge Cash    \n",
        "37                              Judge Parsons    \n",
        "38                                    Kennedy    \n",
        "39                     Kennedy administration    \n",
        "\n",
        "                                       became  \\\n",
        "0                                        ` `    \n",
        "1                                 13 primary    \n",
        "2               Birmingham Repertory Company    \n",
        "3                                    British    \n",
        "4                                    Chicago    \n",
        "5    Christian Anti-Communist Crusade school    \n",
        "6                  Communist Chinese demands    \n",
        "7                          Communist leaders    \n",
        "8                       Communist operations    \n",
        "9                            Communist state    \n",
        "10                                 Confusion    \n",
        "11                                    Dunkel    \n",
        "12                                    French    \n",
        "13                                    Friday    \n",
        "14                                    Geneva    \n",
        "15                             German market    \n",
        "16                              German pilot    \n",
        "17                                   Germany    \n",
        "18                                Indo-China    \n",
        "19                             Ivan Allen Jr    \n",
        "20                                       Jim    \n",
        "21                               Judge Smith    \n",
        "22                                      Laos    \n",
        "23                               Los Angeles    \n",
        "24                                   Lumumba    \n",
        "25                               Macwhyte Co    \n",
        "26                              Marin county    \n",
        "27                          Mayor Hartsfield    \n",
        "28                                     Miami    \n",
        "29                                       Mrs    \n",
        "30                  National Audubon Society    \n",
        "31                            North Viet Nam    \n",
        "32                Northwest district manager    \n",
        "33                                        P.    \n",
        "34                                    Police    \n",
        "35                        President Kasavubu    \n",
        "36  Reed Rogers Da Fonta Wild Life Sanctuary    \n",
        "37                                   Russian    \n",
        "38                      San Francisco Giants    \n",
        "39                                      Sept    \n",
        "\n",
        "                                  called                        gave  \n",
        "0                              industry                        Laos   \n",
        "1                            Government                      States   \n",
        "2                                    Mr                    one time   \n",
        "3                             President                     trouble   \n",
        "4                             Secretary                         065   \n",
        "5                                  able                    1-0 lead   \n",
        "6                                  case                   1961 shot   \n",
        "7                               efforts        3-game total offense   \n",
        "8                               opinion           380-foot home run   \n",
        "9                                police                   512 yards   \n",
        "10                              problem              545-yard spree   \n",
        "11                racial discrimination   6-foot-3-inch 158-pounder   \n",
        "12                               report                         A's   \n",
        "13                                today                   Athletics   \n",
        "14                           $100 check                 Auntie Mame   \n",
        "15               10 witnesses yesterday                    Beardens   \n",
        "16                           102 joints                 Bill Tuttle   \n",
        "17                            145 yards                       Birds   \n",
        "18                             26 times                 Bob Allison   \n",
        "19                       ADC dependency                     British   \n",
        "20                            Americans                    Broadway   \n",
        "21                        Arab Republic                   Cardinals   \n",
        "22                     Attorney General   Communist Chinese demands   \n",
        "23                      Barbara Borland        Communist operations   \n",
        "24                       Belgian troops             Communist state   \n",
        "25                            Ben Stein                  Communists   \n",
        "26                             Bourcier                       Corps   \n",
        "27                          Buchheister                        D.C.   \n",
        "28                            Composite        Field's long service   \n",
        "29                            Congolese     Frank Cipriani's single   \n",
        "30                 Congolese Government                      French   \n",
        "31   County Supervisor Weldon R. Sheets                      Geneva   \n",
        "32                   Cuban tractor plan            Harmon Killebrew   \n",
        "33                                   D.                        Hyde   \n",
        "34  Democratic gubernatorial nomination                  Indo-China   \n",
        "35                   Desmond D. Connall                  Jim Landis   \n",
        "36                              Detroit                      Keegan   \n",
        "37                    Drexel collection     Ku Klux Klan membership   \n",
        "38                            Education                   Longhorns   \n",
        "39                                Egypt    Lovely Thrush Annamorena   "
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Output on the mystery collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = GetMysteryText()\n",
      "sents = GetSentencesFromMystery(text)\n",
      "result = GetNounPhrasesAssociatedWithImportantVerbs(GetTaggedSentences(sents),sents)\n",
      "df = pd.DataFrame(result)\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>averaged</th>\n",
        "      <th>began</th>\n",
        "      <th>believed</th>\n",
        "      <th>bought</th>\n",
        "      <th>intervened</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>                          year </td>\n",
        "      <td>                                     Corp </td>\n",
        "      <td>                             markets </td>\n",
        "      <td>                        dollars </td>\n",
        "      <td>                                            Japan </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>                           EIA </td>\n",
        "      <td>                                     MMTC </td>\n",
        "      <td>                                   \" </td>\n",
        "      <td>                        dealers </td>\n",
        "      <td>                                             Bank </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>               Gasoline demand </td>\n",
        "      <td>                                   Metals </td>\n",
        "      <td>                               Baker </td>\n",
        "      <td>                           Bank </td>\n",
        "      <td>                                           dollar </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>          residual fuel demand </td>\n",
        "      <td>                                 Minerals </td>\n",
        "      <td>                              dollar </td>\n",
        "      <td>                          Japan </td>\n",
        "      <td>                                          dollars </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>                    38 mln bpd </td>\n",
        "      <td>                                      STC </td>\n",
        "      <td>                        500 mln dlrs </td>\n",
        "      <td>                  trade sources </td>\n",
        "      <td>                                          150 yen </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>                    40 mln bpd </td>\n",
        "      <td>                                    State </td>\n",
        "      <td>                     57 insecticides </td>\n",
        "      <td>                   central bank </td>\n",
        "      <td>                                          dealers </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>                         7 pct </td>\n",
        "      <td>                             countertrade </td>\n",
        "      <td>                    Japanese economy </td>\n",
        "      <td>                           year </td>\n",
        "      <td>                                    major nations </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>                         9 pct </td>\n",
        "      <td>                                    firms </td>\n",
        "      <td>                    Monetary sources </td>\n",
        "      <td>                         20 yen </td>\n",
        "      <td>                                     small amount </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> Domestic crude oil production </td>\n",
        "      <td>                                  impetus </td>\n",
        "      <td>                Swiss bank economist </td>\n",
        "      <td>                         30 yen </td>\n",
        "      <td>                                           Canada </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>                           SPR </td>\n",
        "      <td>                                two state </td>\n",
        "      <td>                     Tokyo's package </td>\n",
        "      <td>                     723 tonnes </td>\n",
        "      <td>                 Finance Minister Kiichi Miyazawa </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>                     Wednesday </td>\n",
        "      <td>                                     week </td>\n",
        "      <td> U.S. Treasury Secretary James Baker </td>\n",
        "      <td>                           ASCS </td>\n",
        "      <td>                                           France </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>     gross daily crude imports </td>\n",
        "      <td>                                   40 pct </td>\n",
        "      <td>                                 ban </td>\n",
        "      <td>                  EGYPT BUYS PL </td>\n",
        "      <td>                                            Paris </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>                         1 pct </td>\n",
        "      <td>               93-nation world trade body </td>\n",
        "      <td>                          government </td>\n",
        "      <td>                          India </td>\n",
        "      <td>                                            Tokyo </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>                        15 mln </td>\n",
        "      <td>                                September </td>\n",
        "      <td>                      lower-yielding </td>\n",
        "      <td>                   Indian goods </td>\n",
        "      <td>                                             U.S. </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>                        23 pct </td>\n",
        "      <td>                            Uruguay trade </td>\n",
        "      <td>                   major stimulation </td>\n",
        "      <td>                         Moscow </td>\n",
        "      <td>                                     West Germany </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>                         3 pct </td>\n",
        "      <td>                                     area </td>\n",
        "      <td>                            movement </td>\n",
        "      <td>                             PL </td>\n",
        "      <td>                                        committee </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>                  393 mln dlrs </td>\n",
        "      <td>                                     case </td>\n",
        "      <td>                            outbreak </td>\n",
        "      <td>               U.S. wheat flour </td>\n",
        "      <td>                          major nations yesterday </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>                        43 mln </td>\n",
        "      <td>                                   dollar </td>\n",
        "      <td>                              period </td>\n",
        "      <td> WHEAT FLOUR U.S. TRADERS Egypt </td>\n",
        "      <td>                                      six Britain </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>                        44 mln </td>\n",
        "      <td>                                    lands </td>\n",
        "      <td>                               ready </td>\n",
        "      <td>                       aircraft </td>\n",
        "      <td>                                              yen </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>                        45 pct </td>\n",
        "      <td>                                sunflower </td>\n",
        "      <td>                            reserves </td>\n",
        "      <td>                  better chance </td>\n",
        "      <td>                                 150 yen Miyazawa </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>                         5 pct </td>\n",
        "      <td>                                    today </td>\n",
        "      <td>                           resistant </td>\n",
        "      <td>              commerce ministry </td>\n",
        "      <td>                                           50 yen </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>                        53 mln </td>\n",
        "      <td>                                 000 feet </td>\n",
        "      <td>                resistant rice types </td>\n",
        "      <td>          early afternoon trade </td>\n",
        "      <td>                              85 yen dealers Bank </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>                    67 mln bpd </td>\n",
        "      <td>                                20 30 yen </td>\n",
        "      <td>                                rice </td>\n",
        "      <td>              foreign companies </td>\n",
        "      <td> 85 yen dealers NAKASONE SAYS DOLLAR FALL ONLY ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>                    75 mln bpd </td>\n",
        "      <td>                                 25 years </td>\n",
        "      <td>                             sources </td>\n",
        "      <td>                        opening </td>\n",
        "      <td>                                 Japan intervenes </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>                        97 mln </td>\n",
        "      <td>                               600 tonnes </td>\n",
        "      <td>                           targetted </td>\n",
        "      <td>              railway equipment </td>\n",
        "      <td>                                     Tokyo market </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>                           day </td>\n",
        "      <td>                        Brazilian exports </td>\n",
        "      <td>         two-week borrowings average </td>\n",
        "      <td>                         return </td>\n",
        "      <td>                                    U.S. Currency </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>                        high 6 </td>\n",
        "      <td> European coffee trade federation meeting </td>\n",
        "      <td>                                 use </td>\n",
        "      <td>                           rigs </td>\n",
        "      <td>                                     central bank </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>                net borrowings </td>\n",
        "      <td>                        European position </td>\n",
        "      <td>                           varieties </td>\n",
        "      <td>                       services </td>\n",
        "      <td>                                              dlr </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>                         tonne </td>\n",
        "      <td>                                October 1 </td>\n",
        "      <td>                              wereng </td>\n",
        "      <td>                          ships </td>\n",
        "      <td>                              dollar's sharp fall </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>                          week </td>\n",
        "      <td>                               October 13 </td>\n",
        "      <td>                           yesterday </td>\n",
        "      <td>                   small amount </td>\n",
        "      <td>                                            house </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td>                       08 dlrs </td>\n",
        "      <td>                             Soviet Union </td>\n",
        "      <td>                              \" USDA </td>\n",
        "      <td>               tender yesterday </td>\n",
        "      <td>                                     medium-sized </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td>                        08 mln </td>\n",
        "      <td>              U.S. Agriculture Department </td>\n",
        "      <td>                        1 mln ounces </td>\n",
        "      <td>                           week </td>\n",
        "      <td>                                     post-war low </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td>                        09 mln </td>\n",
        "      <td>         U.S. USSR Grain Supply Agreement </td>\n",
        "      <td>                              15 pct </td>\n",
        "      <td>                     0 mln dlrs </td>\n",
        "      <td>                                         pressure </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td>                    11 mln bpd </td>\n",
        "      <td>                                U.S. corn </td>\n",
        "      <td> 35 billion dlr supplementary budget </td>\n",
        "      <td>                       000 bags </td>\n",
        "      <td>                                       stable dlr </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>                    15 mln bpd </td>\n",
        "      <td>  USSR ADDS U.S. CORN TO COMMITMENTS USDA </td>\n",
        "      <td>                      5 billion dlrs </td>\n",
        "      <td>                     000 tonnes </td>\n",
        "      <td>                                   support dollar </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>                        18 mln </td>\n",
        "      <td>                                afternoon </td>\n",
        "      <td>                       65 mln tonnes </td>\n",
        "      <td>                       043 dlrs </td>\n",
        "      <td>                                        temporary </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td>                          1987 </td>\n",
        "      <td>                                  company </td>\n",
        "      <td>                            Brasilia </td>\n",
        "      <td>                     1 mln dlrs </td>\n",
        "      <td> \" BANK OF JAPAN INTERVENES JUST AFTER TOKYO OP...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>                  265 mln dlrs </td>\n",
        "      <td>                                  dealers </td>\n",
        "      <td>                              Bulolo </td>\n",
        "      <td>                   1 mln pounds </td>\n",
        "      <td>                                           00 yen </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td>               36 billion dlrs </td>\n",
        "      <td>                                 delivery </td>\n",
        "      <td>                              Darman </td>\n",
        "      <td>                         10 yen </td>\n",
        "      <td>                                              147 </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td>                        39 mln </td>\n",
        "      <td>                                  diamond </td>\n",
        "      <td>                 European currencies </td>\n",
        "      <td>                   18 companies </td>\n",
        "      <td> 150 yen G-6 WANTS TO HOLD DLR ABOVE 150 YEN NA...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "                          averaged                                      began  \\\n",
        "0                            year                                       Corp    \n",
        "1                             EIA                                       MMTC    \n",
        "2                 Gasoline demand                                     Metals    \n",
        "3            residual fuel demand                                   Minerals    \n",
        "4                      38 mln bpd                                        STC    \n",
        "5                      40 mln bpd                                      State    \n",
        "6                           7 pct                               countertrade    \n",
        "7                           9 pct                                      firms    \n",
        "8   Domestic crude oil production                                    impetus    \n",
        "9                             SPR                                  two state    \n",
        "10                      Wednesday                                       week    \n",
        "11      gross daily crude imports                                     40 pct    \n",
        "12                          1 pct                 93-nation world trade body    \n",
        "13                         15 mln                                  September    \n",
        "14                         23 pct                              Uruguay trade    \n",
        "15                          3 pct                                       area    \n",
        "16                   393 mln dlrs                                       case    \n",
        "17                         43 mln                                     dollar    \n",
        "18                         44 mln                                      lands    \n",
        "19                         45 pct                                  sunflower    \n",
        "20                          5 pct                                      today    \n",
        "21                         53 mln                                   000 feet    \n",
        "22                     67 mln bpd                                  20 30 yen    \n",
        "23                     75 mln bpd                                   25 years    \n",
        "24                         97 mln                                 600 tonnes    \n",
        "25                            day                          Brazilian exports    \n",
        "26                         high 6   European coffee trade federation meeting    \n",
        "27                 net borrowings                          European position    \n",
        "28                          tonne                                  October 1    \n",
        "29                           week                                 October 13    \n",
        "30                        08 dlrs                               Soviet Union    \n",
        "31                         08 mln                U.S. Agriculture Department    \n",
        "32                         09 mln           U.S. USSR Grain Supply Agreement    \n",
        "33                     11 mln bpd                                  U.S. corn    \n",
        "34                     15 mln bpd    USSR ADDS U.S. CORN TO COMMITMENTS USDA    \n",
        "35                         18 mln                                  afternoon    \n",
        "36                           1987                                    company    \n",
        "37                   265 mln dlrs                                    dealers    \n",
        "38                36 billion dlrs                                   delivery    \n",
        "39                         39 mln                                    diamond    \n",
        "\n",
        "                                believed                           bought  \\\n",
        "0                               markets                          dollars    \n",
        "1                                     \"                          dealers    \n",
        "2                                 Baker                             Bank    \n",
        "3                                dollar                            Japan    \n",
        "4                          500 mln dlrs                    trade sources    \n",
        "5                       57 insecticides                     central bank    \n",
        "6                      Japanese economy                             year    \n",
        "7                      Monetary sources                           20 yen    \n",
        "8                  Swiss bank economist                           30 yen    \n",
        "9                       Tokyo's package                       723 tonnes    \n",
        "10  U.S. Treasury Secretary James Baker                             ASCS    \n",
        "11                                  ban                    EGYPT BUYS PL    \n",
        "12                           government                            India    \n",
        "13                       lower-yielding                     Indian goods    \n",
        "14                    major stimulation                           Moscow    \n",
        "15                             movement                               PL    \n",
        "16                             outbreak                 U.S. wheat flour    \n",
        "17                               period   WHEAT FLOUR U.S. TRADERS Egypt    \n",
        "18                                ready                         aircraft    \n",
        "19                             reserves                    better chance    \n",
        "20                            resistant                commerce ministry    \n",
        "21                 resistant rice types            early afternoon trade    \n",
        "22                                 rice                foreign companies    \n",
        "23                              sources                          opening    \n",
        "24                            targetted                railway equipment    \n",
        "25          two-week borrowings average                           return    \n",
        "26                                  use                             rigs    \n",
        "27                            varieties                         services    \n",
        "28                               wereng                            ships    \n",
        "29                            yesterday                     small amount    \n",
        "30                               \" USDA                 tender yesterday    \n",
        "31                         1 mln ounces                             week    \n",
        "32                               15 pct                       0 mln dlrs    \n",
        "33  35 billion dlr supplementary budget                         000 bags    \n",
        "34                       5 billion dlrs                       000 tonnes    \n",
        "35                        65 mln tonnes                         043 dlrs    \n",
        "36                             Brasilia                       1 mln dlrs    \n",
        "37                               Bulolo                     1 mln pounds    \n",
        "38                               Darman                           10 yen    \n",
        "39                  European currencies                     18 companies    \n",
        "\n",
        "                                           intervened  \n",
        "0                                              Japan   \n",
        "1                                               Bank   \n",
        "2                                             dollar   \n",
        "3                                            dollars   \n",
        "4                                            150 yen   \n",
        "5                                            dealers   \n",
        "6                                      major nations   \n",
        "7                                       small amount   \n",
        "8                                             Canada   \n",
        "9                   Finance Minister Kiichi Miyazawa   \n",
        "10                                            France   \n",
        "11                                             Paris   \n",
        "12                                             Tokyo   \n",
        "13                                              U.S.   \n",
        "14                                      West Germany   \n",
        "15                                         committee   \n",
        "16                           major nations yesterday   \n",
        "17                                       six Britain   \n",
        "18                                               yen   \n",
        "19                                  150 yen Miyazawa   \n",
        "20                                            50 yen   \n",
        "21                               85 yen dealers Bank   \n",
        "22  85 yen dealers NAKASONE SAYS DOLLAR FALL ONLY ...  \n",
        "23                                  Japan intervenes   \n",
        "24                                      Tokyo market   \n",
        "25                                     U.S. Currency   \n",
        "26                                      central bank   \n",
        "27                                               dlr   \n",
        "28                               dollar's sharp fall   \n",
        "29                                             house   \n",
        "30                                      medium-sized   \n",
        "31                                      post-war low   \n",
        "32                                          pressure   \n",
        "33                                        stable dlr   \n",
        "34                                    support dollar   \n",
        "35                                         temporary   \n",
        "36  \" BANK OF JAPAN INTERVENES JUST AFTER TOKYO OP...  \n",
        "37                                            00 yen   \n",
        "38                                               147   \n",
        "39  150 yen G-6 WANTS TO HOLD DLR ABOVE 150 YEN NA...  "
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Other Algorithms"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "I tried an algorithm to get the most frequent noun phrases in a chrnonological fashion to try and then group these phrases to reduce the number of phrases and also get a gist of the narration. This was based on the idea that key phrases depend on the context of the story as this is a narration rather than a news."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This methods checks the similarity between two words\n",
      "def IsSimilar(string1, string2):\n",
      "    if string1 == string2:\n",
      "        return True\n",
      "    if len(string1) >  len(string2):\n",
      "        tokens = string1.split(\" \")\n",
      "        for token in tokens:\n",
      "            if token == \"\":\n",
      "                continue\n",
      "            if token in string2.split(\" \"):\n",
      "                return True\n",
      "    else:\n",
      "        tokens = string2.split(\" \")\n",
      "        for token in tokens:\n",
      "            if token == \"\":\n",
      "                continue\n",
      "            if token in string1.split(\" \"):\n",
      "                return True\n",
      "    return False\n",
      "\n",
      "#This method gets the noun phrases, grouped together, in the order as they come in the book\n",
      "def GetNPChrono():\n",
      "    words = GetWordsFromFeynman()\n",
      "    fd = nltk.FreqDist(words)\n",
      "    #*tagging important words*\n",
      "    importantwords = [a for a in fd if fd[a]>25 and fd[a] <50]\n",
      "    tagged_impwords = nltk.pos_tag(importantwords)\n",
      "    nounPhrases = ChunkASection(GetTaggedSentences(GetSentencesFromFeynman()),SlightlyModifiedChuangChunker)\n",
      "    pattern = r\"([A-Z]\\.)+|\\w+([-']\\w+)*|\\$?\\d+(\\.\\d+)?%?|\\.\\.\\.|[][.,;\\\"'?():-_`]\"\n",
      "    selectedNPs = [np for np in nounPhrases if (len([imp for imp in importantwords if imp in nltk.regexp_tokenize(np, pattern)]) > 0) ]\n",
      "    selectedNps_mod = selectedNPs\n",
      "    length = len(selectedNps_mod)\n",
      "    i = 0\n",
      "    while i < len(selectedNps_mod):\n",
      "        j = i+1\n",
      "        length = len(selectedNps_mod)\n",
      "        while j < length:\n",
      "            if IsSimilar(selectedNps_mod[i].strip(),selectedNps_mod[j].strip())==True:\n",
      "                del selectedNps_mod[j]\n",
      "                length=length-1\n",
      "            j = j+1\n",
      "        i=i+1\n",
      "    return selectedNps_mod"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "['seven years ', 'story ', 'one person ', 'crazy things ', 'one person ', 'true picture ', 'compulsive need ', 'life ', 'scientific understanding ', 'student ', 'lectures ', 'front ', 'black top ', 'lecture hall ', 'small town ', 'York ', 'MIT ', 'Princeton ', 'Cornell ', 'Brazil ', 'year ', 'house ', 'results ', 'own fuses ', 'old burnt-out fuse ', 'piece ', 'father ', 'worry ', 'head ', 'home ', 'tube radio ', 'radio ', 'situation ', 'house ', 'part ', 'telephone ', 'music ', 'hut ', 'reason people ', 'kinds ', 'job ', 'car ', 'trouble ', 'beginning ', 'hell ', 'matter ', 'wrong order ', 'set ', 'hundred percent ', 'friend ', 'damn thing ', 'safes ', 'high school ', 'math class ', 'twenty minutes ', 'five guys ', 'dance ', 'chop ... \" ', 'answer ', 'daughter stop ', \"mother's name \", 'answer ', '\" six ', 'problems ', 'wonderful practice ', 'right-triangle problems ', 'difference ', 'sin2 cos2 = 1 ', 'five degrees ', 'square root sign ', 'different sign ', 'difference ', 'got-twenty-two dollars ', 'desk clerk ', 'invalid woman ', 'world ', 'group ', 'ten cents ', 'side ', 'old tray ', 'floor ', 'sort ', 'process ', 'six desserts ', 'desk ', 'pull-chain light ', 'light ', 'mind ', 'moment ', 'call ', 'call ', 'MIT ', 'Jewish fraternity ', 'Phi Beta Delta fraternity ', 'fact ', 'questions ', 'morning ', 'fraternity ', 'group ', 'important compromise ', 'various ways ', 'fun ', 'floor ', 'sleep ', 'sir ', 'certain girl ', 'fun ', 'point ', 'point ', 'trick four ', 'hole ', 'hands ', 'whole week ', 'others ', 'sarcastic voice ', 'word ', 'sir ', 'low voice ', 'head ', 'year ', 'conve ideas ', 'reason ', 'class ', 'week ', 'four weeks ', 'feeling ', 'car ', 'moment ', 'process ', 'sleep ', 'interpretation department ', 'name ', 'job ', 'physicists ', 'war ', 'beautiful purple vapor ', 'hands ', 'little company ', 'company ', 'experiments ', 'lots ', 'experiments ', 'wheel ', 'fact ', 'company ', 'Princeton ', 'Princeton ', 'change ', 'home ', 'world ', 'Prof John Wheeler ', 'hole ', 'interesting situation ', 'inside ', 'inside ', 'plant cells ', 'part ', 'lectures ', 'sort ', 'grossest possible error ', 'opposite change ', 'machine shop man ', 'feeling ', 'life ', 'yellow ', 'real works ', 'town ', 'father ', 'certain object ', 'father ', 'ants ', 'plant ', 'ants ', 'ants ', 'ants ', 'piece ', 'army ', 'army ', 'physicists ', 'machine ', 'gear drawings ', 'machine ', 'hands ', 'bomb ', 'bomb ', 'morning ', 'office ', 'letter ', 'letter ', 'difficult writing ', 'letter ', 'trouble ', 'hole ', 'cabinet ', 'important secrets ', 'desk drawer ', 'let ', 'entire plant ', 'bad memory ', 'plant ', 'war ', 'car ', 'walk ', 'ten cards ', 'ideas ', 'cabinet ', 'combination locks ', 'combination wheel ', 'combination ', 'Ordinary safes ', 'department ', 'cabinet ', 'twenty minutes ', 'minutes ', 'office ', 'war ', 'office ', 'yellow green-it ', 'army ', 'ideas ', 'profound questions ', 'Cornell ', 'dance ', 'graduate student ', 'lots ', 'lecture Marcuso ', 'nuclear reaction ... ', 'voice ', 'good friend ', 'walk ', 'joker 1 ', 'Portuguese well ', 'Brazil ', 'word ', 'small crowd ', 'Brazilian music ', 'drum ', 'music ', 'word ', 'experimental results ', 'Brazil ', 'hundred dollars ', 'John ', \"John Big's assistant \", 'John ', 'woman ', 'year ', 'help ', 'mind ', 'Japanese guy ', 'Japanese style hotel ', 'floor ', 'Japanese guy ', 'kinds ', 'others ', 'point ', 'sign ', 'art ', 'art ', 'damn thing ', 'feeling ', 'sloppy drawings ', 'drawings ', 'picture ', 'such-and-such drawings ', 'picture ', 'art activities ', 'county art museum ', 'wonderful books ', 'side ', 'scientific development ', 'start ', 'hell ', 'various places ', 'York Times ', 'drum ', 'drum ', 'drum ', 'actual playing ', 'scientific investigation ', 'matter ']"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "The problem with this algorithm was that while it was giving a good gist, the key phrases were not getting highlighted. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "I tried another algorithm where I tried to group everything into nounphrase-verb-nounphrase, something of a subject verb predicate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pattern = r\"([A-Z]\\.)+|\\w+([-']\\w+)*|\\$?\\d+(\\.\\d+)?%?|\\.\\.\\.|[][.,;\\\"'?():-_`]\"\n",
      "# xx= [[('Jimmy','NP'), ('said','VB'), ('moon','NN'), ('will','IN'), ('rise','VB')]]\n",
      "NVN_Senences_brown = []\n",
      "#all_subjects_tokens =[]\n",
      "\n",
      "for (verb,count) in brown_verbs[:5]:\n",
      "    all_subj_NPS = []\n",
      "    print \"verb = \",verb\n",
      "    #sents = [sent for sent in brown_tagged_sentences if verb in [word for (word,tag) in sent]]\n",
      "    sents = [sent for sent in brown_sentences if verb in sent]\n",
      "    for sent in sents:\n",
      "        index = sent.index(verb)\n",
      "        subj = sent[0:index]        \n",
      "                \n",
      "        #subj = [w for w in subj if w.lower() not in stopwords.words('english')]\n",
      "        subj = [w for w in subj if w not in string.punctuation]\n",
      "        subj_tagged = nltk.pos_tag(subj)\n",
      "        \n",
      "        nps = ChunkASection([subj_tagged],NounPhraseChunker)\n",
      "        all_subj_NPS += nps\n",
      "        \n",
      "        #obj = sent[index+1:len(sent)]\n",
      "          \n",
      "    subj_NPS_fd = nltk.FreqDist(all_subj_NPS)\n",
      "    print subj_NPS_fd.items()[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "The problem with this code was that approach was that I was not able to clearly identify meaningful predicates even though subjects and verbs were clearly highlighted"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Another approach I tried was tryong to combine verbs with their wordnet hypernyms and matching noun hypernyms to vollocated very hypernyms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synsetDict = {}\n",
      "for verb in verb_list:\n",
      "    syns = wn.synsets(verb.strip(),'v')[0]\n",
      "    print syns\n",
      "    print \"HYP:\" , syns.hypernyms()\n",
      "    #synsetDict[syns].append(verb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "This approach had problems in the sense that all the words did not have hypernyms and it was difficult to get meaningful hypernyms in that context"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}